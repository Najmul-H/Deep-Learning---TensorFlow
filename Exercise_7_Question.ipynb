{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise 7 - Question.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 2",
      "name": "python2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 11563
        },
        "outputId": "9e0d1797-3fa5-4ea8-c7ba-e2694dfb3d09"
      },
      "cell_type": "code",
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n",
        "\n",
        "# Expected Output is extremely large, but should end with:\n",
        "\n",
        "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
        "#                                                                 activation_276[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
        "#                                                                 activation_280[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
        "#                                                                 mixed9_1[0][0]                   \n",
        "#                                                                 concatenate_5[0][0]              \n",
        "#                                                                 activation_281[0][0]             \n",
        "#==================================================================================================\n",
        "#Total params: 21,802,784\n",
        "#Trainable params: 0\n",
        "#Non-trainable params: 21,802,784"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-02 02:16:22--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.197.128, 2607:f8b0:400e:c09::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.197.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M  55.1MB/s    in 1.5s    \n",
            "\n",
            "2019-05-02 02:16:24 (55.1 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1 (BatchNo (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization_v1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_1 (Batch (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_v1_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_2 (Batch (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_v1_2[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_3 (Batch (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_v1_3[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_4 (Batch (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_v1_4[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_8 (Batch (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_8[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_6 (Batch (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_9 (Batch (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_v1_6[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_v1_9[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_5 (Batch (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_7 (Batch (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_10 (Batc (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_11 (Batc (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_5[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_7[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_10[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_v1_11[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_15 (Batc (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_15[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_13 (Batc (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_16 (Batc (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_13[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_16[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_12 (Batc (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_14 (Batc (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_17 (Batc (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_18 (Batc (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_12[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_14[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_17[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_18[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_22 (Batc (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_22[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_20 (Batc (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_23 (Batc (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_20[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_23[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_19 (Batc (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_21 (Batc (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_24 (Batc (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_25 (Batc (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_19[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_21[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_24[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_25[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_27 (Batc (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_27[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_28 (Batc (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_28[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_26 (Batc (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_29 (Batc (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_v1_26[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_v1_29[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_34 (Batc (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_34[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_35 (Batc (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_35[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_31 (Batc (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_36 (Batc (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_31[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_36[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_32 (Batc (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_37 (Batc (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_32[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_37[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_30 (Batc (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_33 (Batc (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_38 (Batc (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_39 (Batc (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_30[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_33[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_38[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_39[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_44 (Batc (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_44[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_45 (Batc (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_45[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_41 (Batc (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_46 (Batc (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_41[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_46[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_42 (Batc (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_47 (Batc (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_42[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_47[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_40 (Batc (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_43 (Batc (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_48 (Batc (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_49 (Batc (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_40[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_43[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_48[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_49[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_54 (Batc (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_54[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_55 (Batc (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_55[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_51 (Batc (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_56 (Batc (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_51[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_56[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_52 (Batc (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_57 (Batc (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_52[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_57[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_50 (Batc (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_53 (Batc (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_58 (Batc (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_59 (Batc (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_50[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_53[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_58[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_59[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_64 (Batc (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_64[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_65 (Batc (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_65[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_61 (Batc (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_66 (Batc (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_61[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_66[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_62 (Batc (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_67 (Batc (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_62[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_67[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_60 (Batc (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_63 (Batc (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_68 (Batc (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_69 (Batc (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_60[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_63[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_68[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_69[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_72 (Batc (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_72[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_73 (Batc (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_73[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_70 (Batc (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_74 (Batc (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_70[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_74[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_71 (Batc (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_75 (Batc (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_71[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_75[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_80 (Batc (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_v1_80[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_77 (Batc (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_81 (Batc (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_77[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_81[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_78 (Batc (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_79 (Batc (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_82 (Batc (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_83 (Batc (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_76 (Batc (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_78[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_79[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_82[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_83[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_84 (Batc (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_76[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_84[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_89 (Batc (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_v1_89[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_86 (Batc (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_90 (Batc (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_86[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_90[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_87 (Batc (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_88 (Batc (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_91 (Batc (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_92 (Batc (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_85 (Batc (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_87[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_88[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_91[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_92[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_93 (Batc (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_85[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_93[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eff046cb-b44b-4897-de92-12e07dc20429"
      },
      "cell_type": "code",
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('last layer output shape: ', (None, 7, 7, 768))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8520
        },
        "outputId": "f8d3e585-b9ca-44ee-ec22-0f95d9f1d025"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model(pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Expected output will be large. Last few lines should be:\n",
        "\n",
        "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
        "#                                                                  activation_251[0][0]             \n",
        "#                                                                  activation_256[0][0]             \n",
        "#                                                                  activation_257[0][0]             \n",
        "# __________________________________________________________________________________________________\n",
        "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
        "# __________________________________________________________________________________________________\n",
        "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
        "# ==================================================================================================\n",
        "# Total params: 47,512,481\n",
        "# Trainable params: 38,537,217\n",
        "# Non-trainable params: 8,975,264\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1 (BatchNo (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization_v1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_1 (Batch (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_v1_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_2 (Batch (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_v1_2[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_3 (Batch (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_v1_3[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_4 (Batch (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_v1_4[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_8 (Batch (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_8[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_6 (Batch (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_9 (Batch (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_v1_6[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_v1_9[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_5 (Batch (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_7 (Batch (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_10 (Batc (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_11 (Batc (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_5[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_7[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_10[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_v1_11[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_15 (Batc (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_15[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_13 (Batc (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_16 (Batc (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_13[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_16[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_12 (Batc (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_14 (Batc (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_17 (Batc (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_18 (Batc (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_12[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_14[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_17[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_18[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_22 (Batc (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_22[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_20 (Batc (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_23 (Batc (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_20[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_23[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_19 (Batc (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_21 (Batc (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_24 (Batc (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_25 (Batc (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_19[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_21[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_24[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_25[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_27 (Batc (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_27[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_28 (Batc (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_28[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_26 (Batc (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_29 (Batc (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_v1_26[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_v1_29[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_34 (Batc (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_34[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_35 (Batc (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_35[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_31 (Batc (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_36 (Batc (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_31[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_36[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_32 (Batc (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_37 (Batc (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_32[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_37[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_30 (Batc (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_33 (Batc (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_38 (Batc (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_39 (Batc (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_30[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_33[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_38[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_39[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_44 (Batc (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_44[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_45 (Batc (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_45[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_41 (Batc (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_46 (Batc (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_41[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_46[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_42 (Batc (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_47 (Batc (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_42[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_47[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_40 (Batc (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_43 (Batc (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_48 (Batc (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_49 (Batc (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_40[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_43[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_48[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_49[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_54 (Batc (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_54[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_55 (Batc (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_55[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_51 (Batc (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_56 (Batc (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_51[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_56[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_52 (Batc (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_57 (Batc (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_52[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_57[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_50 (Batc (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_53 (Batc (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_58 (Batc (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_59 (Batc (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_50[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_53[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_58[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_59[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_64 (Batc (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_64[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_65 (Batc (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_65[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_61 (Batc (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_66 (Batc (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_61[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_66[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_62 (Batc (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_67 (Batc (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_62[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_67[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_60 (Batc (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_63 (Batc (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_68 (Batc (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_69 (Batc (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_60[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_63[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_68[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_69[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "fcc2fe12-6581-4166-8c89-9c237c57ac5c"
      },
      "cell_type": "code",
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-02 02:17:29--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.199.128, 2607:f8b0:400e:c09::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.199.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "/tmp/horse-or-human 100%[===================>] 142.65M  72.3MB/s    in 2.0s    \n",
            "\n",
            "2019-05-02 02:17:31 (72.3 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2019-05-02 02:17:33--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.199.128, 2607:f8b0:400e:c09::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.199.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  51.3MB/s    in 0.2s    \n",
            "\n",
            "2019-05-02 02:17:33 (51.3 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "04280506-e169-499d-aa50-b8c5563bf25d"
      },
      "cell_type": "code",
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "train_horses_dir = os.path.join(train_dir, 'horses') # Directory with our training horse pictures\n",
        "train_humans_dir = os.path.join(train_dir, 'humans') # Directory with our training humans pictures\n",
        "validation_horses_dir = os.path.join(validation_dir, 'horses') # Directory with our validation horse pictures\n",
        "validation_humans_dir = os.path.join(validation_dir, 'humans')# Directory with our validation humanas pictures\n",
        "\n",
        "train_horses_fnames = os.listdir(train_horses_dir)\n",
        "train_humans_fnames = os.listdir(train_humans_dir)\n",
        "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
        "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
        "\n",
        "print(len(train_horses_fnames))\n",
        "print(len(train_humans_fnames))\n",
        "print(len(validation_horses_fnames))\n",
        "print(len(validation_humans_fnames))\n",
        "\n",
        "# Expected Output:\n",
        "# 500\n",
        "# 527\n",
        "# 128\n",
        "# 128"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "527\n",
            "128\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "af0706ae-0a7d-4b58-ae46-da2bd81ea09c"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (150, 150))     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
        "                                                          batch_size  = 20,\n",
        "                                                          class_mode  = 'binary', \n",
        "                                                          target_size = (150, 150))\n",
        "\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes.\n",
        "# Found 256 images belonging to 2 classes."
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1805
        },
        "outputId": "d19eed77-396f-4507-a725-e14a7c62072f"
      },
      "cell_type": "code",
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "\n",
        "callbacks = myCallback()\n",
        "history = model.fit_generator(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 100,\n",
        "            epochs = 100,\n",
        "            validation_steps = 50,\n",
        "            verbose = 2,\n",
        "            callbacks=[callbacks])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/100\n",
            "13/13 [==============================] - 2s 171ms/step - loss: 0.0195 - acc: 0.9922\n",
            " - 15s - loss: 0.2347 - acc: 0.9192 - val_loss: 0.0195 - val_acc: 0.9922\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 1s 110ms/step - loss: 0.0061 - acc: 0.9961\n",
            " - 11s - loss: 0.0909 - acc: 0.9611 - val_loss: 0.0061 - val_acc: 0.9961\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 1s 110ms/step - loss: 6.8157e-04 - acc: 1.0000\n",
            " - 11s - loss: 0.0740 - acc: 0.9688 - val_loss: 6.8157e-04 - val_acc: 1.0000\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 1s 109ms/step - loss: 0.2493 - acc: 0.9609\n",
            " - 12s - loss: 0.0765 - acc: 0.9786 - val_loss: 0.2493 - val_acc: 0.9609\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 0.0037 - acc: 1.0000\n",
            " - 11s - loss: 0.0484 - acc: 0.9825 - val_loss: 0.0037 - val_acc: 1.0000\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 2s 123ms/step - loss: 0.0011 - acc: 1.0000\n",
            " - 12s - loss: 0.0660 - acc: 0.9815 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 0.1104 - acc: 0.9766\n",
            " - 12s - loss: 0.0275 - acc: 0.9883 - val_loss: 0.1104 - val_acc: 0.9766\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 1s 106ms/step - loss: 0.0029 - acc: 1.0000\n",
            " - 11s - loss: 0.0603 - acc: 0.9796 - val_loss: 0.0029 - val_acc: 1.0000\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - 1s 109ms/step - loss: 0.1221 - acc: 0.9805\n",
            " - 11s - loss: 0.0351 - acc: 0.9864 - val_loss: 0.1221 - val_acc: 0.9805\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - 1s 109ms/step - loss: 0.1361 - acc: 0.9805\n",
            " - 11s - loss: 0.0160 - acc: 0.9922 - val_loss: 0.1361 - val_acc: 0.9805\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - 1s 109ms/step - loss: 0.3522 - acc: 0.9531\n",
            " - 11s - loss: 0.0659 - acc: 0.9727 - val_loss: 0.3522 - val_acc: 0.9531\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - 1s 109ms/step - loss: 0.0566 - acc: 0.9883\n",
            " - 13s - loss: 0.0146 - acc: 0.9951 - val_loss: 0.0566 - val_acc: 0.9883\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - 2s 128ms/step - loss: 0.0884 - acc: 0.9883\n",
            " - 13s - loss: 0.0458 - acc: 0.9825 - val_loss: 0.0884 - val_acc: 0.9883\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 0.1063 - acc: 0.9844\n",
            " - 11s - loss: 0.0447 - acc: 0.9873 - val_loss: 0.1063 - val_acc: 0.9844\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - 1s 109ms/step - loss: 0.0173 - acc: 0.9961\n",
            " - 11s - loss: 0.0659 - acc: 0.9825 - val_loss: 0.0173 - val_acc: 0.9961\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - 1s 107ms/step - loss: 0.1485 - acc: 0.9766\n",
            " - 11s - loss: 0.0424 - acc: 0.9883 - val_loss: 0.1485 - val_acc: 0.9766\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - 1s 110ms/step - loss: 0.0759 - acc: 0.9922\n",
            " - 11s - loss: 0.0233 - acc: 0.9903 - val_loss: 0.0759 - val_acc: 0.9922\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 0.1345 - acc: 0.9844\n",
            " - 11s - loss: 0.0330 - acc: 0.9942 - val_loss: 0.1345 - val_acc: 0.9844\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - 1s 107ms/step - loss: 0.1831 - acc: 0.9727\n",
            " - 11s - loss: 0.0405 - acc: 0.9873 - val_loss: 0.1831 - val_acc: 0.9727\n",
            "Epoch 20/100\n",
            "13/13 [==============================] - 2s 126ms/step - loss: 0.0831 - acc: 0.9922\n",
            " - 13s - loss: 0.0152 - acc: 0.9942 - val_loss: 0.0831 - val_acc: 0.9922\n",
            "Epoch 21/100\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 0.1492 - acc: 0.9805\n",
            " - 11s - loss: 0.0162 - acc: 0.9961 - val_loss: 0.1492 - val_acc: 0.9805\n",
            "Epoch 22/100\n",
            "13/13 [==============================] - 1s 110ms/step - loss: 0.2827 - acc: 0.9570\n",
            " - 11s - loss: 0.0391 - acc: 0.9903 - val_loss: 0.2827 - val_acc: 0.9570\n",
            "Epoch 23/100\n",
            "13/13 [==============================] - 1s 106ms/step - loss: 0.0671 - acc: 0.9883\n",
            " - 11s - loss: 0.0176 - acc: 0.9971 - val_loss: 0.0671 - val_acc: 0.9883\n",
            "Epoch 24/100\n",
            "13/13 [==============================] - 1s 109ms/step - loss: 0.2811 - acc: 0.9609\n",
            " - 11s - loss: 0.0256 - acc: 0.9932 - val_loss: 0.2811 - val_acc: 0.9609\n",
            "Epoch 25/100\n",
            "13/13 [==============================] - 1s 107ms/step - loss: 0.2325 - acc: 0.9648\n",
            " - 11s - loss: 0.0213 - acc: 0.9942 - val_loss: 0.2325 - val_acc: 0.9648\n",
            "Epoch 26/100\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 0.2093 - acc: 0.9688\n",
            " - 11s - loss: 0.0092 - acc: 0.9961 - val_loss: 0.2093 - val_acc: 0.9688\n",
            "Epoch 27/100\n",
            "13/13 [==============================] - 2s 127ms/step - loss: 0.2214 - acc: 0.9727\n",
            " - 13s - loss: 0.0245 - acc: 0.9932 - val_loss: 0.2214 - val_acc: 0.9727\n",
            "Epoch 28/100\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 0.1101 - acc: 0.9883\n",
            " - 11s - loss: 0.0112 - acc: 0.9961 - val_loss: 0.1101 - val_acc: 0.9883\n",
            "Epoch 29/100\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 0.3148 - acc: 0.9609\n",
            " - 11s - loss: 0.0701 - acc: 0.9844 - val_loss: 0.3148 - val_acc: 0.9609\n",
            "Epoch 30/100\n",
            "13/13 [==============================] - 1s 106ms/step - loss: 0.1603 - acc: 0.9727\n",
            " - 12s - loss: 0.0284 - acc: 0.9912 - val_loss: 0.1603 - val_acc: 0.9727\n",
            "Epoch 31/100\n",
            "13/13 [==============================] - 1s 107ms/step - loss: 0.1765 - acc: 0.9727\n",
            " - 11s - loss: 0.0205 - acc: 0.9942 - val_loss: 0.1765 - val_acc: 0.9727\n",
            "Epoch 32/100\n",
            "13/13 [==============================] - 1s 106ms/step - loss: 0.2025 - acc: 0.9766\n",
            " - 11s - loss: 0.0265 - acc: 0.9912 - val_loss: 0.2025 - val_acc: 0.9766\n",
            "Epoch 33/100\n",
            "13/13 [==============================] - 1s 107ms/step - loss: 0.1861 - acc: 0.9766\n",
            "\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            " - 11s - loss: 0.0049 - acc: 0.9990 - val_loss: 0.1861 - val_acc: 0.9766\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "fa82b37e-c6aa-4bdf-c374-091831633b4c"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niMrcVwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}